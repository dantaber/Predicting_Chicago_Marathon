{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all data from men (n=20,000) and women (n=18,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_men = open('marathon df_0-20000_2016_men', 'rb')   \n",
    "df_men = pickle.load(f_men)  \n",
    "f_men.close() \n",
    "\n",
    "f_women = open('marathon df_0-18000_2016_women', 'rb')   \n",
    "df_women = pickle.load(f_women)  \n",
    "f_women.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add sex to both\n",
    "df_men['sex'] = 'male'\n",
    "df_women['sex'] = 'female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_men.append(df_women, ignore_index = True)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data management  \n",
    "Several new variables created:  \n",
    "* Convert final time into minutes  \n",
    "* Calculate several measures of variation across 5K intervals  \n",
    "* Convert bib number to integer  \n",
    "* Convert age groups into ordinal variable  \n",
    "* Create dummy variables for sex and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert final time and interval times into minutes\n",
    "# In the process, delete observations where extra columns threw data off\n",
    "df['temp'] = df.finaltime.map(lambda x: x.split(':'))\n",
    "df['len'] = df.temp.map(lambda x: len(x))\n",
    "df = df[df['len'] == 3]\n",
    "\n",
    "df['time'] = df.temp.map(lambda x: int(x[0])*60 + int(x[1]) + int(x[2])/60)\n",
    "del df['temp']\n",
    "del df['len']\n",
    "\n",
    "for i in ['5K', '10K', '15K', '20K', '25K', '30K', '35K', '40K']:\n",
    "    df[i] = df[i].map(lambda x: x/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How pace changed over time and best time\n",
    "df['mintime'] = df.loc[:, ['5K', '10K', '15K', '20K', '25K', '30K', '35K', '40K']].min(axis=1)\n",
    "df['mintime_start'] = df.loc[:, ['5K', '10K', '15K', '20K']].min(axis=1)\n",
    "df['maxtime'] = df.loc[:, ['5K', '10K', '15K', '20K', '25K', '30K', '35K', '40K']].max(axis=1)\n",
    "df['timerange'] = df.maxtime - df.mintime\n",
    "\n",
    "df['start_finish_range'] = (df['5K'] - df['40K']).astype(int)\n",
    "df['start_finish_range_percent'] = ((df['5K'] - df['40K'])*100/df['5K']).astype(float)\n",
    "\n",
    "df['start_range'] = (df['5K'] - df['20K']).astype(int)\n",
    "df['start_range_percent'] = ((df['5K'] - df['20K'])*100/df['5K']).astype(float)\n",
    "\n",
    "df['finish_range'] = (df['25K'] - df['40K']).astype(int)\n",
    "df['finish_range_percent'] = ((df['25K'] - df['40K'])*100/df['25K']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When mintime occurred\n",
    "df['peak_time'] = df[['5K', '10K', '15K', '20K', '25K', '30K', '35K', '40K']].idxmin(axis=1)\n",
    "df['peak_time'] = df.peak_time.map(lambda x: int(x.strip('K')))\n",
    "\n",
    "df['peak_time_start'] = df[['5K', '10K', '15K']].idxmin(axis=1)\n",
    "df['peak_time_start'] = df.peak_time_start.map(lambda x: int(x.strip('K')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate SD across intervals and log transform\n",
    "df['split_std'] = df[['5K', '10K', '15K', '20K', '25K', '30K', '35K', '40K']].std(axis=1)\n",
    "df['split_std_start'] = df[['5K', '10K', '15K', '20K']].std(axis=1)\n",
    "\n",
    "df['log_std'] = df.split_std.map(lambda x: np.log(x+1))\n",
    "df['log_std_start'] = df.split_std_start.map(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate difference from one 5K to next and sum them - overall and first 4 intervals only\n",
    "for i in range(10, 45, 5):\n",
    "    name = 'd' + str(i) + 'K'\n",
    "    df[name] = df[str(i) + 'K'] - df[str(i - 5) + 'K']\n",
    "    df['d' + str(i) + 'K_abs'] = df['d' + str(i) + 'K'].map(lambda x: abs(x))\n",
    "\n",
    "df['delta_sums'] = df[['d10K_abs', 'd15K_abs', 'd20K_abs', 'd25K_abs', \n",
    "                       'd30K_abs', 'd35K_abs', 'd40K_abs']].sum(axis=1)\n",
    "\n",
    "df['delta_sums_start'] = df[['d10K_abs', 'd15K_abs', 'd20K_abs', 'd25K_abs']].sum(axis=1)\n",
    "df['pseudo_gini_start'] = df['delta_sums_start']/df[['5K', '10K', '15K', '20K']].mean(axis=1)\n",
    "\n",
    "for i in range(10, 45, 5):\n",
    "    del df['d' + str(i) + 'K_abs']\n",
    "    \n",
    "df['log_delta_sums'] = df.delta_sums.map(lambda x: np.log(x+1))\n",
    "df['log_delta_sums_start'] = df.delta_sums_start.map(lambda x: np.log(x+1))\n",
    "df['log_gini_start'] = df.pseudo_gini_start.map(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert bib number to integer\n",
    "df['bib'] = df.bib.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert age into an ordinal variable\n",
    "# In the process, collapse some of the youngest and oldest age groups with sparse data\n",
    "age_nums = {\"age_ord\": {\"16-19\": 1, \"20-24\": 1, \"25-29\": 2, \"30-34\": 3,\n",
    "                        \"35-39\": 4, \"40-44\": 5, \"45-49\": 6, \"50-54\": 7,\n",
    "                        \"55-59\": 8, \"60-64\": 9, \"65-69\": 9, \"70-74\": 9,\n",
    "                        \"75-79\": 9, \"80+\": 9}}\n",
    "df['age_ord'] = df.age_group\n",
    "df.replace(age_nums, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop 1 observation who is mis-coded\n",
    "df = df[df.age_ord != 'Group']\n",
    "df['age_ord'] = df.age_ord.map(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummies for gender\n",
    "df_sex = pd.get_dummies(df['sex'])\n",
    "df = pd.concat([df, df_sex], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummies for country\n",
    "# First flag and drop suspicious ones\n",
    "df['country'] = df.country.map(lambda x: x.replace('(', '').replace(')', ''))\n",
    "df['flag'] = df.country.map(lambda x: re.search(r'\\b[A-Z]+\\b', x))\n",
    "df = df[df.flag.map(lambda x: bool(x))]\n",
    "del df['flag']\n",
    "\n",
    "countries = pd.get_dummies(df['country'])\n",
    "df = pd.concat([df, countries], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'marathon df_2016_analysis'\n",
    "fileobj = open(file,'wb') \n",
    "pickle.dump(df,fileobj) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
